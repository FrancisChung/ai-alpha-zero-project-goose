# Act III: Example - Exploration vs Exploitation in Practice üíª

Here's a practical example showing how an agent faces the exploration vs exploitation dilemma:

```python
# The agent evaluates whether to exploit its current knowledge or explore new actions.
state = "Board: Agent one move from winning"

# Option 1: Exploitation ‚Äì go for the known best move
exploitation_action = "Place token at D4"
print(f"[Exploitation] From state: '{state}', the agent selects known best action: '{exploitation_action}'")

# Option 2: Exploration ‚Äì try an unexpected action
exploration_action = "Place token at A1"
print(f"[Exploration] Alternatively, the agent could try: '{exploration_action}' to discover new strategies.")
```

This example shows the dilemma:
- **Exploitation**: Take the winning move (guaranteed immediate success)
- **Exploration**: Try something unexpected (might discover new patterns for future games)

In this specific case, exploitation seems obvious - but in earlier stages of the game, the choice becomes much more complex!

Would you like to "run" this code to see how the agent reasons through this decision?

Perfect! Let me simulate running that code for you:

```
[Exploitation] From state: 'Board: Agent one move from winning', the agent selects known best action: 'Place token at D4'
[Exploration] Alternatively, the agent could try: 'Place token at A1' to discover new strategies.
```

Great! This shows the agent's dilemma in action:

**Exploitation Choice (D4):**
- ‚úÖ Guaranteed win this game
- ‚úÖ Uses proven strategy
- ‚ùå Learns nothing new

**Exploration Choice (A1):**
- ‚ùå Might lose this game
- ‚úÖ Could discover new winning patterns
- ‚úÖ Builds knowledge for future games

In this specific situation, most agents would choose exploitation (take the win!). But imagine if this was early in the game - then exploration might be worth the risk to discover better long-term strategies.

The key insight: **The best choice depends on the situation and the agent's learning goals.** Early in training, agents explore more. As they get better, they exploit more of what they've learned.

This balance is what makes reinforcement learning so powerful - agents don't just follow fixed rules, they adapt their strategy based on what they need to learn!

Ready to continue to Act IV?